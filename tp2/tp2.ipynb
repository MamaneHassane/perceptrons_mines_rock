{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T07:59:16.372477Z",
     "start_time": "2024-12-07T07:59:16.327197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Charge un fichier et retourne une liste de blocs (groupes de 11 lignes).\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Séparer les blocs de 11 lignes\n",
    "        blocks = []\n",
    "        current_block = []\n",
    "\n",
    "        for line in lines:\n",
    "            stripped_line = line.strip()\n",
    "\n",
    "            # Ajouter la ligne au bloc actuel si elle n'est pas vide\n",
    "            if stripped_line:\n",
    "                current_block.append(stripped_line)\n",
    "\n",
    "            # Lorsque le bloc atteint 11 lignes, on l'ajoute et on réinitialise\n",
    "            if len(current_block) == 11:\n",
    "                blocks.append(\"\\n\".join(current_block))\n",
    "                current_block = []\n",
    "\n",
    "        return blocks\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur : Le fichier {filepath} est introuvable.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier {filepath} : {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def classify_and_save_blocks(blocks, classification, train_file, test_file):\n",
    "    \"\"\"\n",
    "    Classifie les blocs en train et test, ajoute la classification et les sauvegarde.\n",
    "    \"\"\"\n",
    "    for block in blocks:\n",
    "        # Extraire la première ligne du bloc\n",
    "        first_line = block.split(\"\\n\")[0].strip()\n",
    "\n",
    "        # Vérifier le type de bloc\n",
    "        if first_line.startswith('*'):  # Train\n",
    "            file = train_file\n",
    "        else:  # Test\n",
    "            file = test_file\n",
    "\n",
    "        # Ajouter le bloc et la classification au fichier\n",
    "        file.write(block + \"\\n\\n\")\n",
    "        file.write(str(classification) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "def save_datasets(mine_file, rocks_file, train_filepath, test_filepath):\n",
    "    \"\"\"Gère la séparation des blocs et leur classification.\"\"\"\n",
    "    try:\n",
    "        # Charger les fichiers\n",
    "        mine_blocks = load_data(mine_file)\n",
    "        rocks_blocks = load_data(rocks_file)\n",
    "\n",
    "        # Ouvrir les fichiers de sortie\n",
    "        os.makedirs(os.path.dirname(train_filepath), exist_ok=True)\n",
    "        with open(train_filepath, 'w', encoding='utf-8') as train_file, \\\n",
    "             open(test_filepath, 'w', encoding='utf-8') as test_file:\n",
    "\n",
    "            # Classifier et sauvegarder les blocs des fichiers \"mines\" et \"rocks\"\n",
    "            classify_and_save_blocks(mine_blocks, 1, train_file, test_file)  # Mines : classification = 1\n",
    "            classify_and_save_blocks(rocks_blocks, -1, train_file, test_file)  # Rocks : classification = -1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création des datasets : {e}\")\n",
    "\n",
    "\n",
    "# Chemins vers les fichiers sources\n",
    "mine_file = '../sonar_data/sonar.mines'\n",
    "rocks_file = '../sonar_data/sonar.rocks'\n",
    "\n",
    "# Chemins des fichiers de sortie\n",
    "train_filepath = 'tp2/result_sets/train_set.txt'\n",
    "test_filepath = 'tp2/result_sets/test_set.txt'\n",
    "\n",
    "# Générer les datasets\n",
    "save_datasets(mine_file, rocks_file, train_filepath, test_filepath)\n",
    "\n",
    "print(\"Les fichiers train_set.txt et test_set.txt ont été créés avec succès !\")\n"
   ],
   "id": "d3c4d7ef92be1091",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers train_set.txt et test_set.txt ont été créés avec succès !\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T07:59:16.404565Z",
     "start_time": "2024-12-07T07:59:16.377002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from classes.ensemble import Ensemble\n",
    "from classes.paire import Paire\n",
    "\n",
    "\n",
    "def lire_fichier_ensemble(filepath):\n",
    "    \"\"\"\n",
    "    Lit un fichier train ou test et crée un objet Ensemble.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Le chemin vers le fichier à lire.\n",
    "\n",
    "    Returns:\n",
    "        Ensemble: Un objet contenant toutes les paires lues depuis le fichier.\n",
    "    \"\"\"\n",
    "    ensemble = Ensemble()\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            ligne = lines[i].strip()\n",
    "            # print(f\"Ligne {i}: {ligne}\")  # Debug pour voir chaque ligne lue\n",
    "\n",
    "            if ligne.startswith('*') or ligne.startswith('CM'):\n",
    "                # Identifie le début d'un bloc\n",
    "                bloc_id = ligne\n",
    "                i += 1\n",
    "                bloc_vecteur = []\n",
    "\n",
    "                # Lire les vecteurs\n",
    "                while i < len(lines) and not lines[i].strip().isdigit():\n",
    "                    vecteur_ligne = lines[i].strip('{} \\n')\n",
    "                    bloc_vecteur.extend([float(val) for val in vecteur_ligne.split()])\n",
    "                    i += 1\n",
    "\n",
    "                # Lire la classification\n",
    "                if i < len(lines) and lines[i].strip().isdigit():\n",
    "                    classification = int(lines[i].strip())\n",
    "                    # print(f\"Bloc {bloc_id}: Classification {classification}\")  # Debug pour la classification\n",
    "                    i += 1\n",
    "                else:\n",
    "                    print(f\"Erreur : Classification manquante pour le bloc {bloc_id}\")\n",
    "                    continue\n",
    "\n",
    "                # Ajouter la paire à l'ensemble\n",
    "                paire = Paire(bloc_vecteur, classification)\n",
    "                # print(f\"Paire ajoutée: {paire}\")  # Debug pour la paire ajoutée\n",
    "                ensemble.ajouter_paire(paire)\n",
    "            else:\n",
    "                i += 1  # Ignorer les lignes non pertinentes\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier {filepath} : {e}\")\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "train_ensemble = lire_fichier_ensemble('tp2/result_sets/train_set.txt')\n",
    "test_ensemble = lire_fichier_ensemble('tp2/result_sets/test_set.txt')\n",
    "\n",
    "# Affichage pour validation\n",
    "print(\"Train Ensemble contient :\", len(train_ensemble.elements), \"paires.\")\n",
    "print(\"Test Ensemble contient :\", len(test_ensemble.elements), \"paires.\")\n",
    "# test_ensemble.dessiner()\n"
   ],
   "id": "5bec2910c125baaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de la lecture du fichier tp2/result_sets/train_set.txt : could not convert string to float: '*CR037:'\n",
      "Train Ensemble contient : 49 paires.\n",
      "Test Ensemble contient : 62 paires.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T07:59:16.467280Z",
     "start_time": "2024-12-07T07:59:16.451500Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "803fac26e8cc644a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
