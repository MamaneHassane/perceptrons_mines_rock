{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T09:09:44.994378Z",
     "start_time": "2024-12-07T09:09:44.958471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Charge un fichier et retourne une liste de blocs (groupes de 11 lignes).\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Séparer les blocs de 11 lignes\n",
    "        blocks = []\n",
    "        current_block = []\n",
    "\n",
    "        for line in lines:\n",
    "            stripped_line = line.strip()\n",
    "\n",
    "            # Ajouter la ligne au bloc actuel si elle n'est pas vide\n",
    "            if stripped_line:\n",
    "                current_block.append(stripped_line)\n",
    "\n",
    "            # Lorsque le bloc atteint 11 lignes, on l'ajoute et on réinitialise\n",
    "            if len(current_block) == 11:\n",
    "                blocks.append(\"\\n\".join(current_block))\n",
    "                current_block = []\n",
    "\n",
    "        return blocks\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur : Le fichier {filepath} est introuvable.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier {filepath} : {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def classify_and_save_blocks(blocks, classification, train_file, test_file):\n",
    "    \"\"\"\n",
    "    Classifie les blocs en train et test, ajoute la classification et les sauvegarde.\n",
    "    \"\"\"\n",
    "    for block in blocks:\n",
    "        # Extraire la première ligne du bloc\n",
    "        first_line = block.split(\"\\n\")[0].strip()\n",
    "\n",
    "        # Vérifier le type de bloc\n",
    "        if first_line.startswith('*'):  # Train\n",
    "            file = train_file\n",
    "        else:  # Test\n",
    "            file = test_file\n",
    "\n",
    "        # Ajouter le bloc et la classification au fichier\n",
    "        file.write(block + \"\\n\\n\")\n",
    "        file.write(str(classification) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "def save_datasets(mine_file, rocks_file, train_filepath, test_filepath):\n",
    "    \"\"\"Gère la séparation des blocs et leur classification.\"\"\"\n",
    "    try:\n",
    "        # Charger les fichiers\n",
    "        mine_blocks = load_data(mine_file)\n",
    "        rocks_blocks = load_data(rocks_file)\n",
    "\n",
    "        # Ouvrir les fichiers de sortie\n",
    "        os.makedirs(os.path.dirname(train_filepath), exist_ok=True)\n",
    "        with open(train_filepath, 'w', encoding='utf-8') as train_file, \\\n",
    "             open(test_filepath, 'w', encoding='utf-8') as test_file:\n",
    "\n",
    "            # Classifier et sauvegarder les blocs des fichiers \"mines\" et \"rocks\"\n",
    "            classify_and_save_blocks(mine_blocks, 1, train_file, test_file)  # Mines : classification = 1\n",
    "            classify_and_save_blocks(rocks_blocks, -1, train_file, test_file)  # Rocks : classification = -1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création des datasets : {e}\")\n",
    "\n",
    "\n",
    "# Chemins vers les fichiers sources\n",
    "mine_file = '../sonar_data/sonar.mines'\n",
    "rocks_file = '../sonar_data/sonar.rocks'\n",
    "\n",
    "# Chemins des fichiers de sortie\n",
    "train_filepath = 'tp2/result_sets/train_set.txt'\n",
    "test_filepath = 'tp2/result_sets/test_set.txt'\n",
    "\n",
    "# Générer les datasets\n",
    "save_datasets(mine_file, rocks_file, train_filepath, test_filepath)\n",
    "\n",
    "print(\"Les fichiers train_set.txt et test_set.txt ont été créés avec succès !\")\n"
   ],
   "id": "d3c4d7ef92be1091",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers train_set.txt et test_set.txt ont été créés avec succès !\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T09:09:45.042310Z",
     "start_time": "2024-12-07T09:09:45.006334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from classes.ensemble import Ensemble\n",
    "from classes.paire import Paire\n",
    "\n",
    "\n",
    "def lire_blocs(filepath):\n",
    "    \"\"\"\n",
    "    Lit un fichier et retourne une liste de blocs (groupes de 14 lignes).\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Le chemin vers le fichier à lire.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste de blocs, chaque bloc est une liste de lignes de vecteurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        blocs = []\n",
    "        i = 0\n",
    "\n",
    "        while i < len(lines):\n",
    "            # Lire 14 lignes pour un bloc\n",
    "            bloc = lines[i:i + 14]\n",
    "            if len(bloc) < 14:\n",
    "                break  # Sortir si le bloc n'est pas complet\n",
    "\n",
    "            blocs.append(bloc)\n",
    "            i += 14  # Passer au bloc suivant\n",
    "\n",
    "        return blocs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier {filepath} : {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def traiter_bloc_en_paire(bloc):\n",
    "    \"\"\"\n",
    "    Transforme un bloc en une paire de vecteurs et de classification.\n",
    "\n",
    "    Args:\n",
    "        bloc (list): Un bloc contenant 14 lignes (vecteurs, nom, classification).\n",
    "\n",
    "    Returns:\n",
    "        Paire: Une instance de `Paire` avec le vecteur et la classification.\n",
    "    \"\"\"\n",
    "    vecteur = []\n",
    "\n",
    "    # Lire les lignes de vecteurs (2ème à 11ème)\n",
    "    for i in range(1, 12):  # On commence à la 1ère ligne (1) jusqu'à la 11ème\n",
    "        ligne_donnees = bloc[i].strip('{} \\n')\n",
    "        if ligne_donnees:  # Ignore les lignes vides\n",
    "            valeurs = [float(val) for val in ligne_donnees.split()]\n",
    "            vecteur.extend(valeurs)\n",
    "\n",
    "    # La 13ème ligne contient la classification\n",
    "    classification_str = bloc[12].strip()  # La ligne vide avant la classification\n",
    "    classification = 1 if classification_str == '1' else -1\n",
    "\n",
    "    return Paire(tuple(vecteur), classification)\n",
    "\n",
    "\n",
    "def construire_ensemble(filepath):\n",
    "    \"\"\"\n",
    "    Crée un Ensemble à partir d'un fichier train ou test.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Le chemin vers le fichier à lire.\n",
    "\n",
    "    Returns:\n",
    "        Ensemble: Un objet `Ensemble` contenant toutes les paires lues depuis le fichier.\n",
    "    \"\"\"\n",
    "    ensemble = Ensemble()\n",
    "    try:\n",
    "        blocs = lire_blocs(filepath)\n",
    "        if not blocs:\n",
    "            return ensemble\n",
    "\n",
    "        for bloc in blocs:\n",
    "            paire = traiter_bloc_en_paire(bloc)\n",
    "            if paire:\n",
    "                ensemble.ajouter_paire(paire)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création de l'ensemble depuis {filepath} : {e}\")\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "train_ensemble = construire_ensemble('tp2/result_sets/train_set.txt')\n",
    "test_ensemble = construire_ensemble('tp2/result_sets/test_set.txt')\n",
    "\n",
    "# Affichage pour validation\n",
    "print(\"Train Ensemble contient :\", len(train_ensemble.elements), \"paires.\")\n",
    "print(\"Test Ensemble contient :\", len(test_ensemble.elements), \"paires.\")\n",
    "# print(train_ensemble)\n",
    "# print(test_ensemble)"
   ],
   "id": "5bec2910c125baaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Ensemble contient : 104 paires.\n",
      "Test Ensemble contient : 104 paires.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T09:09:45.090119Z",
     "start_time": "2024-12-07T09:09:45.076724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def creer_all_ensemble(train_filepath, test_filepath):\n",
    "    train_ensemble = construire_ensemble(train_filepath)\n",
    "    test_ensemble = construire_ensemble(test_filepath)\n",
    "\n",
    "    # Créer un nouvel ensemble qui combine les paires des deux ensembles\n",
    "    all_ensemble = Ensemble(*train_ensemble.elements, *test_ensemble.elements)\n",
    "\n",
    "    return all_ensemble\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "all_ensemble = creer_all_ensemble('tp2/result_sets/train_set.txt', 'tp2/result_sets/test_set.txt')\n",
    "\n",
    "# Affichage pour validation\n",
    "print(\"All Ensemble contient :\", len(all_ensemble.elements), \"paires.\")\n",
    "print(all_ensemble)"
   ],
   "id": "803fac26e8cc644a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
