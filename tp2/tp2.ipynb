{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:46:36.657631Z",
     "start_time": "2024-12-06T20:46:36.603419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Charge un fichier et retourne une liste de blocs (groupes de 11 lignes).\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Séparer les blocs de 11 lignes\n",
    "        blocks = []\n",
    "        current_block = []\n",
    "\n",
    "        for line in lines:\n",
    "            stripped_line = line.strip()\n",
    "\n",
    "            # Ajouter la ligne au bloc actuel si elle n'est pas vide\n",
    "            if stripped_line:\n",
    "                current_block.append(stripped_line)\n",
    "\n",
    "            # Lorsque le bloc atteint 11 lignes, on l'ajoute et on réinitialise\n",
    "            if len(current_block) == 11:\n",
    "                blocks.append(\"\\n\".join(current_block))\n",
    "                current_block = []\n",
    "\n",
    "        return blocks\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur : Le fichier {filepath} est introuvable.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier {filepath} : {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def classify_and_save_blocks(blocks, classification, train_file, test_file):\n",
    "    \"\"\"\n",
    "    Classifie les blocs en train et test, ajoute la classification et les sauvegarde.\n",
    "    \"\"\"\n",
    "    for block in blocks:\n",
    "        # Extraire la première ligne du bloc\n",
    "        first_line = block.split(\"\\n\")[0].strip()\n",
    "\n",
    "        # Vérifier le type de bloc\n",
    "        if first_line.startswith('*'):  # Train\n",
    "            file = train_file\n",
    "        else:  # Test\n",
    "            file = test_file\n",
    "\n",
    "        # Ajouter le bloc et la classification au fichier\n",
    "        file.write(block + \"\\n\\n\")\n",
    "        file.write(str(classification) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "def save_datasets(mine_file, rocks_file, train_filepath, test_filepath):\n",
    "    \"\"\"Gère la séparation des blocs et leur classification.\"\"\"\n",
    "    try:\n",
    "        # Charger les fichiers\n",
    "        mine_blocks = load_data(mine_file)\n",
    "        rocks_blocks = load_data(rocks_file)\n",
    "\n",
    "        # Ouvrir les fichiers de sortie\n",
    "        os.makedirs(os.path.dirname(train_filepath), exist_ok=True)\n",
    "        with open(train_filepath, 'w', encoding='utf-8') as train_file, \\\n",
    "             open(test_filepath, 'w', encoding='utf-8') as test_file:\n",
    "\n",
    "            # Classifier et sauvegarder les blocs des fichiers \"mines\" et \"rocks\"\n",
    "            classify_and_save_blocks(mine_blocks, 1, train_file, test_file)  # Mines : classification = 1\n",
    "            classify_and_save_blocks(rocks_blocks, -1, train_file, test_file)  # Rocks : classification = -1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création des datasets : {e}\")\n",
    "\n",
    "\n",
    "# Chemins vers les fichiers sources\n",
    "mine_file = 'sonar_data/sonar.mines'\n",
    "rocks_file = 'sonar_data/sonar.rocks'\n",
    "\n",
    "# Chemins des fichiers de sortie\n",
    "train_filepath = 'tp2/result_sets/train_set.txt'\n",
    "test_filepath = 'tp2/result_sets/test_set.txt'\n",
    "\n",
    "# Générer les datasets\n",
    "save_datasets(mine_file, rocks_file, train_filepath, test_filepath)\n",
    "\n",
    "print(\"Les fichiers train_set.txt et test_set.txt ont été créés avec succès !\")\n"
   ],
   "id": "d3c4d7ef92be1091",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers train_set.txt et test_set.txt ont été créés avec succès !\n"
     ]
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:46:45.753957Z",
     "start_time": "2024-12-06T20:46:45.715405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from classes.ensemble import Ensemble\n",
    "from classes.paire import Paire\n",
    "\n",
    "def lire_fichier_ensemble(filepath):\n",
    "    \"\"\"\n",
    "    Lit un fichier train ou test et crée un objet Ensemble.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Le chemin vers le fichier à lire.\n",
    "\n",
    "    Returns:\n",
    "        Ensemble: Un objet contenant toutes les paires lues depuis le fichier.\n",
    "    \"\"\"\n",
    "    ensemble = Ensemble()\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            lines = [line.strip() for line in file if line.strip()]  # Supprime les lignes vides\n",
    "            i = 0\n",
    "\n",
    "            while i < len(lines):\n",
    "                bloc_donnees = []\n",
    "\n",
    "                # Lire les lignes jusqu'à rencontrer une ligne vide ou un en-tête\n",
    "                while i < len(lines) and lines[i] and not lines[i].startswith('*') and not lines[i].startswith('CM'):\n",
    "                    bloc_donnees.append(lines[i])\n",
    "                    i += 1\n",
    "\n",
    "                # Si on n'a pas assez de lignes pour former un bloc valide, on arrête\n",
    "                if len(bloc_donnees) < 12:\n",
    "                    break\n",
    "\n",
    "                # La 13ème ligne contient la classification\n",
    "                classification_str = lines[i].strip()\n",
    "                if classification_str.startswith('*') or classification_str.startswith('CM'):\n",
    "                    continue  # Ignorer les en-têtes de bloc\n",
    "\n",
    "                try:\n",
    "                    classification = int(classification_str)\n",
    "                    i += 1\n",
    "                except ValueError:\n",
    "                    print(f\"Erreur : Classification invalide pour le bloc : {classification_str}\")\n",
    "                    continue\n",
    "\n",
    "                # Convertir les données en un vecteur de floats en combinant toutes les lignes du bloc\n",
    "                vecteur = []\n",
    "                for data_line in bloc_donnees:\n",
    "                    vecteur.extend([float(val) for val in data_line.strip('{}').split(',')])\n",
    "\n",
    "                # Créer une paire et l'ajouter à l'ensemble\n",
    "                paire = Paire(vecteur, classification)\n",
    "                print(paire)\n",
    "                ensemble.ajouter_paire(paire)\n",
    "\n",
    "                # Sauter la ligne vide avant de passer au bloc suivant\n",
    "                i += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier {filepath} : {e}\")\n",
    "    return ensemble\n",
    "\n",
    "# Exemple d'utilisation\n",
    "train_ensemble = lire_fichier_ensemble('tp2/result_sets/train_set.txt')\n",
    "test_ensemble = lire_fichier_ensemble('tp2/result_sets/test_set.txt')\n",
    "\n",
    "# Affichage pour validation\n",
    "print(\"Train Ensemble contient :\", len(train_ensemble.elements), \"paires.\")\n",
    "print(\"Test Ensemble contient :\", len(test_ensemble.elements), \"paires.\")\n"
   ],
   "id": "5bec2910c125baaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Ensemble contient : 0 paires.\n",
      "Test Ensemble contient : 0 paires.\n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:46:45.778429Z",
     "start_time": "2024-12-06T20:46:45.772832Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "803fac26e8cc644a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
